# MCP 学习笔记

## 一、初识 MCP

### （一）切入——传统旅行规划的痛点

- 传统方式需花费大量时间筛选信息、规划路线和管理预订，过程繁琐，比较容易削弱出行期待。

- 大语言模型（LLM）在旅行规划中存在认知局限——大多数用户将LLM视作高级信息检索工具或知识问答系统，这导致其中的听一些潜力尚未被充分挖掘——*如个性化推荐、动态优化等*，且受模型幻觉影响，实用性不足。

### （二）无 MCP 时的旅行规划~

- 以黄山三日游规划为例，乍一看，其输出结果似乎具备一定的吸引力和可行性

  但是仔细一瞅，大语言模型输出的规划存在预算超支、车次信息不准确（eg:12306 官网无法查询）等问题。

  因此，这份旅游规划成功落地的可能性有待考证~

### （三）有 MCP 时的旅行规划！

- 本节将使用Trae，并在其中配置好高德MCP Server（配置过程详见4.1.3节）。配置完成后，在“设置”界面切换到“MCP”选项卡，即可看到多个可用的MCP Server（见书图1-3）。

- **在Trae模型对话框中，点击“@Agent”图标并选择Builder with MCP模式，再次输入前文提示词。**

  此模式下，你可以自主选择MCP Server完成任务并查看效果。 

- 就像（书中）图 1-4 里那样，大语言模型做了个 4 月 25 到 27 号的黄山三日游规划，里面有详细的天气预报、路线怎么走，还有每天花多少钱这些。里面多数信息准确，只有第一天早上6:30的高铁信息没查到。

  不过总的来说，这个规划差不多能用，比没接高德 MCP Server 时做的行程好多了。

**同一大语言模型在相同提示词下输出差异大，是因为后来接入了 MCP Server。从旅行行程案例能看出其强大便捷，那么 MCP 究竟是什么呢？**

## 二、MCP 的发展历程与现状

MCP 的崛起并非一蹴而就，而是长期积累后的爆发。自 2024 年 11 月发布以来，历经数月的沉淀与迭代，MCP 于 2025 年实现爆发式增长，成为当年科技领域备受瞩目的焦点之一。

 接下来，我们将追溯 MCP 的发展历程，剖析其当前的发展态势，并展望其未来的广阔前景，力求为读者呈现一幅关于 MCP 的全景图景。

### （一）发展历史

- MCP由 Anthropic （美国 AI 初创公司）主导开发，MCP 旨在解决大语言模型与第三方系统集成的复杂性问题。

  其设计受语言服务器协议（LSP）启发，采用 JSON-RPC 2.0 作为通信基础，基于成熟技术构建。

- 早期被 Block、Apollo 等公司采用，生态快速增长，截至完稿时 MCP Server 达 7000 余个。

  主流 AI 提供商（OpenAI、谷歌 DeepMind 等）及国内阿里、百度等均宣布支持或推出相关平台（详见第五章）。

### （二）MCP现状

- 2025 年，“MCP” 在科技领域迅速崛起，引发广泛关注。从最初的默默无闻，到各大科技巨头纷纷背书，互联网上对其解读众说纷纭，因此需依据官方文档厘清其定义。

  官方明确，**MCP 是一种开放的应用层协议**。

  - “**开放”** 意味着它公开、非专有，鼓励社区参与，旨在实现广泛采纳与互操作性，避免厂商锁定

- - 作为**应用层协议**，它工作于 OSI 或 TCP/IP 模型的应用层，专注定义应用间通信的语义和规则，抽象了底层网络的复杂细节。

- **核心目标**是**规范 AI 系统各组成部分（AI 模型、软件工具、API等）的上下文信息交换与交互行为**：
  -  这里的**“组成部分”** 范围极广，涵盖各类 AI 模型、传统软件工具、API乃至用户交互界面

- - **上下文信息**包括用户偏好、会话历史、领域知识、实时环境数据、当前任务状态、系统能力与约束等，既可为静态或动态，也可为短期或长期。

- **愿景**：通过统一消息格式、请求响应模式等，打破信息壁垒，构建完善、高效、和谐的智能协同生态，实现组件协同，有望孕育 “涌现智能”。

## 三、MCP 的未来：统一AI 应用标准接口

MCP 的未来核心目标之一是**为 AI 应用提供标准化接口**，以此简化 AI 能力的集成、管理与协同，推动 AI 生态的开放与创新。

这一标准化接口主要体现在三个核心方面，层层递进地支撑起 MCP 的价值：

### （一）统一工具调用标准

- 复杂 AI 应用常需调用多种来源、功能的工具，而各工具独有的 API 和数据格式会增加集成与维护成本。

  MCP 通过 “统一工具调用标准” 解决这一问题，具体包含两部分：

  - **标准化工具能力描述**：要求每个 MCP 客户端（工具）以统一元数据格式声明能力。

    包括**唯一标识符**（如名称、版本号，确保准确引用）、**功能描述**（自然语言说明工具能执行的任务）、**输入参数规范**（明确参数名、类型、是否必需等，支持从共享上下文动态获取参数）。

- - **标准化交互方法**：定义**核心协议方法与通知**，规范 **MCP 主机与客户端的交互流程**。

    包括**工具发现**（主机查询可用工具及能力）、**工具执行**（主机调用工具并传递参数，参数可直接提供或引用上下文数据）、**工具执行结果 / 进度通知**（同步结果直接返回，异步结果通过标准化通知推送）。

- 通过这种标准化，开发者可采用统一编程模型与各类 AI 工具交互，大幅简化开发；AI 模型（尤其是 LLM）也更易生成符合规范的调用请求。

### （二）动态工具集成机制

在统一调用标准的基础上，MCP 进一步支持动态工具集成，赋予了 AI 应用的灵活性与可扩展性 —— 让 AI 应用从静态功能集合转变为能实时适配需求的动态平台，具体体现在：

- **运行时工具发现与加载**：主机可通过工具发现机制或服务发现协议，在运行时主动找到并连接网络中的 MCP 客户端，无需重启即可扩展功能；
- **插件化架构**：支持将 AI 工具封装为独立插件，用户可按需部署、启用或停用（如智能客服动态加载特定知识库插件）；
- **按需服务与资源优化**：对不常用或高资源消耗工具，主机可按需激活，任务完成后释放连接，提升资源利用率；
- **版本管理与依赖协商**：初始化时交换协议与接口版本信息，客户端声明能力依赖版本，主机据此选择兼容工具，甚至解决依赖冲突。

这种动态集成让 AI 应用能快速适应需求变化，集成新技术，构建更健壮的系统。

### （三）语义对齐策略

- *统一语法接口解决了 “如何说” 的问题*，但更深层的互操作性障碍在于 “说什么”—— 确保各方对共享上下文和工具参数的语义理解一致。

  MCP 通过系列机制实现语义对齐：

  - **上下文模式与数据字典**：用明确模式（如 JSON Schema）定义上下文数据的结构、类型、约束及业务含义，配套数据字典说明字段的业务意义（如 user_location 是 GPS 坐标还是 IP 推断城市）；
  - **共享词汇表与本体库**：特定领域用共享词汇表规范术语（如电商的订单状态），用本体库（基于 RDF/RDFS 等语言）描述概念及关系（如产品类别、品牌），让上下文数据关联到本体，赋予计算机可处理的语义；
  - **元数据描述与溯源**：上下文除数据本身外，还包含来源（哪个组件生成）、时间戳（生成 / 更新时间）等元数据；
  - **上下文协商与转换服务**：异构系统交互时，组件可协商上下文格式与语义，或通过转换服务实现不同语义表示的映射。
    这些机制为构建语义一致的智能 AI 系统奠定基础，让 AI 模型能更深层理解上下文，做出更精准的决策。

  综上，这三方面共同构成了 MCP 赋能 AI 应用的核心价值。

  作为开放的应用层协议，MCP 的根本目标始终是通过标准化上下文信息的交换，打破 AI 组件间的信息壁垒，推动更高效、协同的智能生态。

## 四、MCP 的优势与应用

​	MCP 的价值不仅在于前瞻性的理论构想，更体现在切实的落地能力上。其核心优势与生态构建，以及与其他集成方法的对比，更能凸显其独特性：

#### 一、MCP 的核心优势：依托完善生态降低门槛

MCP 能快速普及，关键在于其构建了成熟的开发工具与生态系统，具体表现为：

- **多语言 SDK 支持**：
  - Anthropic 官方提供 TypeScript、Python、Java 等主流编程语言的 SDK，部分与微软（C# SDK）、JetBrains（Kotlin SDK）等巨头合作维护，既提升了 SDK 质量，也增强了公信力；
  - OpenAI 的 Agents SDK 也内置对 MCP 的支持，方便开发者连接不同 MCP Server。
- **活跃的社区生态**：社区贡献了数千个 MCP Server 实现，覆盖 GitHub、Slack、Blender 等多类系统，还涌现出 MCP Inspector 等辅助工具（用于可视化测试），丰富了应用场景。

这些生态优势带来显著价值：*SDK 抽象底层协议，让开发者专注业务逻辑，降低学习与使用门槛；巨头合作背书增强开发者信心；庞大的工具与服务器生态形成网络效应，吸引更多用户加入，形成正向循环。*

#### (二)、MCP 与其他 AI 集成方法的对比：凸显标准化与开放性

为更清晰理解 MCP 的独特价值，可将其与传统及现有集成方法对比：

|              对比维度               | 传统 / 其他集成方法                                          | MCP（模型上下文协议）                                        |
| :---------------------------------: | ------------------------------------------------------------ | ------------------------------------------------------------ |
|  **1. 自定义集成与 API 密钥管理**   | 需为每个服务编写自定义代码，手动处理 API 密钥；新增数据源需开发新代码，难以扩展，系统脆弱。 | 集中标准化交互，AI 代理仅需对接 MCP，新 MCP Server 可即插即用，无需修改客户端代码；提供规范化身份验证结构，确保 API 密钥管理安全可靠。 |
| **2. ChatGPT 插件（OpenAI 插件）**  | 属专有方法，仅支持特定平台；每个插件需单独构建 / 托管，多为单次调用，缺乏持久连接与持续交互。 | 开放通用协议，不依赖特定提供者；支持丰富双向交互与持续上下文，任何开发者或 AI 平台可利用；通过标准认证（如 OAuth）统一处理用户数据安全访问，实现 AI 与服务的持久连贯 “对话”。 |
| **3. LLM 工具框架（如 LangChain）** | 需开发者定义工具函数与代理逻辑，需定制实现（库中维护数百个集成）；缺乏模型运行时动态发现新工具的能力，本质是面向开发者的标准（如 Python 类接口）。 | 将标准化转向 “面向模型”，支持代理动态发现和使用任何 MCP Server 提供的工具（无需代码预集成）；通过协议（如 JSON-RPC）规范化接口，适配多环境（不限于 Python 框架）。与 OpenAI 函数调用协同：LLM 生成结构化调用，MCP Client/Server 执行并返回结果，实现工具无缝使用。 |

综上，MCP 通过标准化、开放性与生态优势，解决了传统集成方法的低效与局限，成为更灵活、可扩展的 AI 集成方案。

#### (三）典型应用场景

MCP 凭借其灵活的标准化特性，能够广泛应用于多种场景，有效增强 AI 系统的能力，以下是其典型应用场景的具体体现：

1. 企业助手：企业利用 MCP，使其内部的 AI 助手能够安全地访问和检索来自专有文档、CRM 系统以及公司内部知识库的信息，从而提高员工的工作效率。
2. 自然语言数据访问：如 AI2SQL 这样的应用通过 MCP 将大语言模型与 SQL 数据库连接起来，使得用户可以用自然语言进行数据库查询，降低了数据访问的技术门槛。
3. 桌面助手：Anthropic 的 Claude Desktop 应用便是一个很好的例子，它在本地运行 MCP Server，允许 AI 助手安全地读取本地文件或与操作系统工具进行交互。 
4. 多工具智能体：MCP 支持涉及多个工具的复杂智能体工作流。例如，一个智能体可能需要先从文档中查找信息，然后通过消息 API 将结果发送出去。MCP 使得这种跨分布式资源的 “思维链” 推理成为可能。
5. 集成开发环境：如 Cursor 这样的 IDE 利用 MCP 实现 AI 驱动的代码辅助功能，帮助开发者自动处理复杂的编程任务，提升开发效率。
6. 云服务集成：Cloudflare推出了远程 MCP Server 托管服务，允许客户端无缝连接到安全的、云托管的 MCP Server，这为企业级应用提供了可扩展性和跨设备互操作性。
